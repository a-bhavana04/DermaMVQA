{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhav1\\anaconda3\\envs\\knowledge-graph\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\bhav1\\anaconda3\\envs\\knowledge-graph\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\bhav1\\anaconda3\\envs\\knowledge-graph\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [02:52<00:00, 86.12s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00, 10.80s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=HF_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    "    use_auth_token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful, respectful, and knowledgeable dermatology assistant.\n",
    "You provide accurate, precise, and safe answers related to dermatological diseases and treatments.\n",
    "Always base your answers on the provided context. If you don't have enough context, say:\n",
    "\"I don't have enough information based on the provided context.\"\n",
    "Cite URLs whenever possible to support your responses.\n",
    "\"\"\"\n",
    "\n",
    "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT):\n",
    "    B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "    B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    return B_INST + SYSTEM_PROMPT + instruction + E_INST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def scrape_pubmed(keyword):\n",
    "    try:\n",
    "        response = requests.get(f\"https://pubmed.ncbi.nlm.nih.gov/?term={keyword}\")\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        results = []\n",
    "        for element in soup.select('.docsum-content'):\n",
    "            title_tag = element.select_one('.docsum-title')\n",
    "            title = title_tag.text.strip() if title_tag else ''\n",
    "            link = f\"https://pubmed.ncbi.nlm.nih.gov{title_tag['href']}\" if title_tag and title_tag.has_attr('href') else ''\n",
    "            authors = element.select_one('.full-authors').text.strip() if element.select_one('.full-authors') else ''\n",
    "            snippet = element.select_one('.docsum-snippet').text.strip() if element.select_one('.docsum-snippet') else ''\n",
    "            abstract = ''\n",
    "\n",
    "            if link:\n",
    "                try:\n",
    "                    article_response = requests.get(link)\n",
    "                    article_response.raise_for_status()\n",
    "                    article_soup = BeautifulSoup(article_response.text, 'html.parser')\n",
    "                    abstract_tag = article_soup.select_one('.abstract-content')\n",
    "                    abstract = abstract_tag.text.strip() if abstract_tag else ''\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching abstract for {link}: {e}\")\n",
    "\n",
    "            results.append({\n",
    "                'title': title,\n",
    "                'link': link,\n",
    "                'authors': authors,\n",
    "                'snippet': snippet,\n",
    "                'abstract': abstract\n",
    "            })\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping PubMed: {e}\")\n",
    "        return []\n",
    "\n",
    "pubmed_data = scrape_pubmed(\"psoriasis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=doc[\"abstract\"],  \n",
    "        metadata={\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"link\": doc[\"link\"],\n",
    "            \"authors\": doc[\"authors\"],\n",
    "            \"snippet\": doc[\"snippet\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in pubmed_data if doc.get(\"abstract\") \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhav1\\AppData\\Local\\Temp\\ipykernel_22792\\2458018583.py:3: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedding=HuggingFaceEmbeddings(),\n"
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=HuggingFaceEmbeddings(),\n",
    "    persist_directory=\"./dermatology_db\"\n",
    ")\n",
    "\n",
    "instruction = (\n",
    "    \"Given the context that has been provided:\\n\"\n",
    "    \"{context}\\n\"\n",
    "    \"Answer the following question:\\n{question}\"\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"\\\n",
    "You are an expert in dermatology.\n",
    "You will be given a context to answer questions from.\n",
    "Be precise in your answers and provide citations when possible.\n",
    "If you are unsure, say \"I don't have enough information based on the provided context.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "class DermatologyBot:\n",
    "    def __init__(self, memory, prompt, retriever):\n",
    "        self.memory = memory\n",
    "        self.prompt = prompt\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def create_chat_bot(self, max_new_tokens=512):\n",
    "        hf_pipe = create_pipeline(max_new_tokens)\n",
    "        llm = HuggingFacePipeline(pipeline=hf_pipe)\n",
    "\n",
    "        qa = ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm,\n",
    "            retriever=self.retriever,\n",
    "            memory=self.memory,\n",
    "            return_source_documents=True,\n",
    "            combine_docs_chain_kwargs={\"prompt\": self.prompt}\n",
    "        )\n",
    "        return qa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhav1\\AppData\\Local\\Temp\\ipykernel_22792\\945011768.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = get_prompt(instruction, system_prompt)\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(max_new_tokens=512):\n",
    "    return pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "class DermatologyBot:\n",
    "    def __init__(self, memory, prompt, retriever):\n",
    "        self.memory = memory\n",
    "        self.prompt = prompt\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def create_chat_bot(self, max_new_tokens=512):\n",
    "        hf_pipe = create_pipeline(max_new_tokens)\n",
    "        llm = HuggingFacePipeline(pipeline=hf_pipe)\n",
    "        qa = ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm,\n",
    "            retriever=self.retriever,\n",
    "            memory=self.memory,\n",
    "            combine_docs_chain_kwargs={\"prompt\": self.prompt}\n",
    "        )\n",
    "        return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "def format_citations(docs):\n",
    "    \"\"\"\n",
    "    Format citations from retrieved documents.\n",
    "    \"\"\"\n",
    "    citations = []\n",
    "    for doc in docs:\n",
    "        title = doc.metadata.get(\"title\", \"Unknown Title\")\n",
    "        link = doc.metadata.get(\"link\", \"No Link Available\")\n",
    "        citations.append(f\"- {title}: {link}\")\n",
    "    return \"\\n\".join(citations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "dermatology_bot = DermatologyBot(memory=memory, prompt=prompt, retriever=retriever)\n",
    "bot = dermatology_bot.create_chat_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the treatments for psoriasis?\"\n",
    "result = bot({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "retrieved_docs = result[\"source_documents\"] \n",
    "citations = format_citations(retrieved_docs)\n",
    "final_response = f\"{answer}\\n\\nCitations:\\n{citations}\"\n",
    "print(final_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        page_content=doc[\"abstract\"],\n",
    "        metadata={\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"link\": doc[\"link\"],\n",
    "            \"authors\": doc[\"authors\"],\n",
    "            \"snippet\": doc[\"snippet\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in pubmed_data if doc.get(\"abstract\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ollamaNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading langchain_ollama-0.2.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from langchain-ollama) (0.3.30)\n",
      "Collecting ollama<1,>=0.4.4 (from langchain-ollama)\n",
      "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (0.1.129)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.27.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\bhav1\\appdata\\roaming\\python\\python311\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.7.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bhav1\\anaconda3\\envs\\knowledge-graph\\lib\\site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.2.3)\n",
      "Downloading langchain_ollama-0.2.2-py3-none-any.whl (18 kB)\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama, langchain-ollama\n",
      "Successfully installed langchain-ollama-0.2.2 ollama-0.4.7\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "chroma_db = Chroma.from_documents(documents, embedding=embeddings, persist_directory=\"./dermatology_db\")\n",
    "\n",
    "llm = OllamaLLM(model=\"llama2\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=chroma_db.as_retriever(search_kwargs={\"k\": 5}),  \n",
    "    return_source_documents=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The treatments for psoriasis include:\n",
      "\n",
      "1. Topical therapy: Corticosteroids, vitamin D analogues, and retinoids can be applied directly to the skin to reduce inflammation and slow down cell growth.\n",
      "2. Phototherapy: Exposure to ultraviolet (UV) light, either from natural sources or through artificial UV light therapy, can help to reduce inflammation and slow down cell growth.\n",
      "3. Systemic therapy: Oral or injected medications such as methotrexate, cyclosporine, and TNF-alpha inhibitors can be used to treat psoriasis. These medications work throughout the body and can have a more significant impact on the disease than topical or phototherapy.\n",
      "4. Biologic therapy: This type of treatment uses genetically engineered drugs that target specific proteins involved in the immune system. Examples include adalimumab, etanercept, and ustekinumab. These medications can be effective in treating moderate to severe psoriasis.\n",
      "5. Laser therapy: Exposure to specific wavelengths of laser light can help to reduce inflammation and slow down cell growth.\n",
      "6. Lifestyle changes: Making lifestyle changes such as maintaining a healthy diet, exercising regularly, and managing stress can help to improve overall health and reduce the symptoms of psoriasis.\n",
      "7. Alternative therapies: Some people find alternative therapies such as acupuncture, herbal remedies, and mind-body practices helpful in managing their psoriasis.\n",
      "\n",
      "It's important to note that what works best for one person may not work for another, so it's often a matter of trial and error to find the most effective treatment approach. A healthcare professional can help determine the best course of treatment for an individual based on the severity and location of their psoriasis, as well as any other health considerations.\n",
      "\n",
      "Citations:\n",
      "- Psoriasis: epidemiology, clinical features, and quality of life.: https://pubmed.ncbi.nlm.nih.gov/15708928/\n",
      "- Psoriasis: epidemiology, clinical features, and quality of life.: https://pubmed.ncbi.nlm.nih.gov/15708928/\n",
      "- Psoriasis: epidemiology, clinical features, and quality of life.: https://pubmed.ncbi.nlm.nih.gov/15708928/\n",
      "- Generalized pustular psoriasis: a review and update on treatment.: https://pubmed.ncbi.nlm.nih.gov/29573491/\n",
      "- Generalized pustular psoriasis: a review and update on treatment.: https://pubmed.ncbi.nlm.nih.gov/29573491/\n"
     ]
    }
   ],
   "source": [
    "def ask_question(query):\n",
    "    result = qa_chain({\"query\": query})\n",
    "    answer = result[\"result\"]\n",
    "    source_docs = result[\"source_documents\"]\n",
    "\n",
    "    citations = \"\\n\".join([\n",
    "        f\"- {doc.metadata.get('title', 'No Title')}: {doc.metadata.get('link', 'No Link')}\"\n",
    "        for doc in source_docs\n",
    "    ])\n",
    "\n",
    "    return f\"{answer}\\n\\nCitations:\\n{citations}\"\n",
    "\n",
    "query = \"What are the treatments for psoriasis?\"\n",
    "response = ask_question(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
